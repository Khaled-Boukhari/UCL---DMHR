{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMHR Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SYSD6 - Leeds "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Useful Libraries Into Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My first line of code are to import the libraries essential for this project. These include the Numpy, Pandas and Matplotlib libraries for python. \n",
    "\n",
    "By importing these libraries as abbreviated terms (e.g. pandas as pd), it is more convinient to access functions and methods fomr them as well as reducing code, making it easier to read when revising or critically evaluating at a later date.\n",
    "\n",
    "* The numpy library contains many useful methods and functions for mathematical calculations and the manipulation of arrays, for example.\n",
    "\n",
    "\n",
    "* The Pandas library utilises powerful data structures as well as containing efficient tools for manipulating the data loaded into these. In many cases, manipulation of data using pythons in-built libraries would take minuites, whereas specialised code within the pandas library can carry out what is effectively the same task in a matter of seconds. \n",
    "\n",
    "\n",
    "* The Scipy library will be used to conduct linear regressions and provide descriptive statistics to populate visualisations with.\n",
    "\n",
    "\n",
    "* The matplotlib library contains functions that contribute to a highly flexible and effective platform for the visualisation of data, it can be used in conjunction with other libraries, booth in-built and imported into python (Pandas also incorporates some features from matplotlib). Overall, this provides data scientists with the tools required for creating plots that are  visually pleasing, can convey insights from many differnt types of data and analyse datasets larger than is practical or realistically possible with other commonly used software.\n",
    "    * '%matplotlib inline' instructs python to produce plots without opening a popup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using an exclamation mark before code, commands form elsewhere in the system can be accessed. The `pip install` command can install external libraries such as `pandasql`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install PandaSQL: !pip install pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandasql import PandaSQL\n",
    "pdsql = PandaSQL()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the dataframes for this investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in first 100 rows of the prescribing dataset in order to guage which columns i will be needing, based on my objectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assigning URL to variables as a string, for use\n",
    "# in reading into pandas dataframes.\n",
    "url_prescription_data = \\\n",
    "    'https://s3.eu-west-2.amazonaws.com' +\\\n",
    "    '/dmhr-data/prescribing_Dec2015.csv'\n",
    "    \n",
    "url_practice_data = \\\n",
    "    'https://s3.eu-west-2.amazonaws.com' +\\\n",
    "    '/dmhr-data/practices_Dec2015.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 11 columns):\n",
      " SHA                                            100 non-null object\n",
      "PCT                                             100 non-null object\n",
      "PRACTICE                                        100 non-null object\n",
      "BNF CODE                                        100 non-null object\n",
      "BNF NAME                                        100 non-null object\n",
      "ITEMS                                           100 non-null int64\n",
      "NIC                                             100 non-null float64\n",
      "ACT COST                                        100 non-null float64\n",
      "QUANTITY                                        100 non-null int64\n",
      "PERIOD                                          100 non-null int64\n",
      "                                                100 non-null object\n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 8.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Read first 100 rows of prescribing data and present information\n",
    "# about columns.\n",
    "\n",
    "pd.read_csv(url_prescription_data, nrows=100).info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will only need: \n",
    "\n",
    "* Practice codes\n",
    "* Drug names\n",
    "* Number of prescriptions\n",
    "* Actual cost of prescriptions\n",
    "* Quantity of units of a drug prescribed\n",
    "\n",
    "These correspond to columns with index: 2, 4, 5, 7 and 8.\n",
    "\n",
    "By including the option `usecols` as equal to a list of the column indexes nessesary, pandas will only read in and create a dataframe restricted to those columns. This will use less RAM as well as allowing the data to be read in faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assign variable to GP prescribing data, select list of\n",
    "# columns read to dataframe.\n",
    "\n",
    "prescribing_data_all = \\\n",
    "    pd.read_csv(url_prescription_data,\n",
    "                usecols=[2, 4, 5, 7, 8])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the fist 10 rows of the practice dataset shows that there are not column headers. Also there is a final column with no header or contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in first 10 rows from URL and display first 5\n",
    "pd.read_csv(url_practice_data,\n",
    "            nrows=10).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in only the column headers further reveals that the cells of this dataframe contain large ammounts of whitespace. removing this will reduce memory usage as well as making the data easier to handle.\n",
    "\n",
    "As this dataset is relatively small I will not exclude any columns, except for the first column, containing the date and the final empty column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in first 10 rows from URL and display column headers\n",
    "pd.read_csv(url_practice_data,\n",
    "            nrows=10).columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I have manually added column headers based on the information provided within them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>practice_code</th>\n",
       "      <th>practice_name</th>\n",
       "      <th>building_name</th>\n",
       "      <th>street</th>\n",
       "      <th>city</th>\n",
       "      <th>region</th>\n",
       "      <th>post_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A81002</td>\n",
       "      <td>QUEENS PARK MEDICAL CENTRE</td>\n",
       "      <td>QUEENS PARK MEDICAL CTR</td>\n",
       "      <td>FARRER STREET</td>\n",
       "      <td>STOCKTON ON TEES</td>\n",
       "      <td>CLEVELAND</td>\n",
       "      <td>TS18 2AW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A81003</td>\n",
       "      <td>VICTORIA MEDICAL PRACTICE</td>\n",
       "      <td>THE HEALTH CENTRE</td>\n",
       "      <td>VICTORIA ROAD</td>\n",
       "      <td>HARTLEPOOL</td>\n",
       "      <td>CLEVELAND</td>\n",
       "      <td>TS26 8DB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  practice_code                             practice_name  \\\n",
       "0        A81002  QUEENS PARK MEDICAL CENTRE                 \n",
       "1        A81003  VICTORIA MEDICAL PRACTICE                  \n",
       "\n",
       "               building_name                     street  \\\n",
       "0  QUEENS PARK MEDICAL CTR    FARRER STREET               \n",
       "1  THE HEALTH CENTRE          VICTORIA ROAD               \n",
       "\n",
       "                        city                     region  \\\n",
       "0  STOCKTON ON TEES           CLEVELAND                   \n",
       "1  HARTLEPOOL                 CLEVELAND                   \n",
       "\n",
       "                   post_code  \n",
       "0  TS18 2AW                   \n",
       "1  TS26 8DB                   "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning list of column headers for the dataframe to\n",
    "# to be read in.\n",
    "practice_columns = ['practice_code', 'practice_name',\n",
    "                    'building_name', 'street',\n",
    "                    'city', 'region', 'post_code']\n",
    "\n",
    "# Read in GP practice dataset into pandas dataframe\n",
    "# with practice_columns list as headers.\n",
    "practice_data_all = \\\n",
    "    pd.read_csv(url_practice_data,\n",
    "                usecols=[1,2,3,4,5,6,7])\n",
    "    \n",
    "practice_data_all.columns = practice_columns\n",
    "\n",
    "practice_data_all.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have defined 3 functions, for the cleaning of these datasets: \n",
    "* The first function strips whitespace out of columns headers. \n",
    "* The second function strips whitespace form all objects in the data frame, provided they are of the string object type.\n",
    "* The third and final function comines the previous two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Defining a function to remove whiespace form column headers, if\n",
    "# column header cell contains a string.\n",
    "def col_tidy(data_frame):\n",
    "    new_data_columns = []\n",
    "    for i in data_frame.columns:\n",
    "        if type(i) == str:\n",
    "            i = i.strip()\n",
    "            i = i.lower()\n",
    "        new_data_columns.append(i)\n",
    "    data_frame.columns = new_data_columns\n",
    "    \n",
    "# Defnining a function to strip whitespace from cells in dataframe\n",
    "# if those cells contain objects.\n",
    "# My laptop struggled with object_tidy. It may not be the most \n",
    "# efficient code for this purpose.\n",
    "# An .apply(Lambda) function would be more efficient in this case\n",
    "def object_tidy(data_frame):\n",
    "    for i in data_frame:\n",
    "        if data_frame[i].dtype == object:\n",
    "            data_frame.loc[:, i] = \\\n",
    "                (data_frame.loc[:, i]).str.strip()\n",
    "            data_frame.loc[:, i] = \\\n",
    "                (data_frame.loc[:, i]).str.lower()           \n",
    "\n",
    "# Defining a function that combines the previous two functions to\n",
    "# clean both column headers and cells form whitespace.\n",
    "def dataframe_clean(data_frame):\n",
    "    col_tidy(data_frame)\n",
    "    object_tidy(data_frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The col_tidy function was used on the prescribing data dataframe as the columns contained a large quantity of whitespace. This was simply done to aid my manipulation of this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_tidy(prescribing_data_all)\n",
    "prescribing_data_all.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsetting to create new dataframes for the prescription data of Leeds and Cambridge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first methodologicl problems I have encountered is the definition of which regions consititute as being part of the cities Leeds and Cambridge. Both cities have distinct postcodes, LS and CB, respectively. However, these postcodes extend far beyond what reasonably be considered areas within the two cities. \n",
    "\n",
    "Furthermore, if I subset the practice data by rows, for which the region variable contains the city in question it often picks up satellite towns. These towns may or may not be included in Leeds, depending on the definition used. For example, Morely and Bramley, the first two towns in the subset below are towns outside of Leeds. Despite this they are included in the metropolitan borough of Leeds. \n",
    "\n",
    "As I have not been briefed on what definition to judge the boundaries of these cities by, I have decided that I will include all practices, for which the city name is included in the city or region. Furthermore, though I will not be using the postcode to filter these out, it will be used as a sanity test to remove any practices that are not in that region of the country. \n",
    "* E.g. Some rows in the subset created from the keyword 'leeds' in both the region and city columns gave pracices which were in the PE (Peterborough) postcode area. These will be filtered out.\n",
    "\n",
    "To do this, I will use .str.contains to assign a boolean value to True to rows containing the city name in either ('|') the region or city columns. case = False, to find strings that contain this word, regardless of case.\n",
    "\n",
    "The further filtering done by using .str.contains() to remove rows that do not contain the relevant postcode may include irrelevant postcodes if the combination of letters occurs in the postcodes second half. I did not encounter this problem, likely due to the new dataframes being relativley small. If this were a problem I could use a regular expression, such as '^' to specify that I want to only find rows for which the postcode contains the letters at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe containing rows that contain the phrase\n",
    "# 'leeds', case insensitive in either the 'city' or 'region' column\n",
    "leeds_practices = \\\n",
    "    practice_data_all.loc[practice_data_all['region']\\\n",
    "                          .str.contains('leeds', case=False) | \\\n",
    "                          practice_data_all['city']\\\n",
    "                          .str.contains('leeds', case=False)]\n",
    "\n",
    "# Further subsetting the leeds practices for rows only containing\n",
    "# the Leeds postcode as a sanity check.\n",
    "leeds_practices = \\\n",
    "    leeds_practices.loc[leeds_practices['post_code']\\\n",
    "                            .str.contains('ls', case=False)]\n",
    "\n",
    "# Process is repeated for Cambridge.\n",
    "cambridge_practices = \\\n",
    "    practice_data_all.loc[practice_data_all['region']\\\n",
    "                          .str.contains('cambridge', case=False) | \\\n",
    "                          practice_data_all['city']\\\n",
    "                          .str.contains('cambridge', case=False)]\n",
    "    \n",
    "cambridge_practices = \\\n",
    "    cambridge_practices.loc[cambridge_practices['post_code']\\\n",
    "                            .str.contains('cb', case=False)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dataframes contained fewer than 200 rows, The max displayed rows and columns were increased to manually check all observations. Here, only the top 5 are displayed as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting options of pandas to display more rows and columns.\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "leeds_practices.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cambridge_practices.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating subsets of the practice dataframe, containing practice data for Leeds and Cambridge, I will use practice codes from these to filter prescribing data for the practices.\n",
    "\n",
    "* Firstly, I will create lists fo the preactice codes for both these cities.\n",
    "* Next, I will subset the prescribing dataframe based on rows containing these practice codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Converting the 'practice_code' series of both dataframes into a list.\n",
    "cambridge_practice_codes = list(cambridge_practices['practice_code'])\n",
    "leeds_practice_codes = list(leeds_practices['practice_code'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subsetting prescribing data based on rows, for which practice code appears\n",
    "# practice code list of its city. The series are parssed as strings with \n",
    "# .contains() function used, case insensitivity is not requuired.\n",
    "# '|' regex used to join practice lists, as and OR logical.\n",
    "prescribing_data_leeds = \\\n",
    "    prescribing_data_all.loc[prescribing_data_all['practice']\n",
    "                             .str.contains('|'.join(leeds_practice_codes))]\n",
    "\n",
    "prescribing_data_cambridge = \\\n",
    "    prescribing_data_all.loc[prescribing_data_all['practice']\n",
    "                             .str.contains('|'.join(cambridge_practice_codes))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \n",
    "By grouping the prescribing data by practice code and applying the .sum() function to it, a new datframe can be made. Here, each practice is reduced to a single row, with the index being its practice code and each column containing the sum of each variable for that practice.\n",
    "\n",
    "Then, by setting the axis as the practice code, fo the practice dataframes of each city, they can be merged with the new prescribing dataframes for their respective cities.\n",
    "\n",
    "This produces a dataframe with the details of each practice and its total number of prescriptions, total cost of prescriptions and the total number of units of drugs prescribed.\n",
    "\n",
    "**The leeds_merged dataframe contains a list of all GP practices in the city of Leeds, along with their total spend on prescriptions ('act cost') and number of unique prescriptions made ('items').**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grouping prescribing datafranes by unique objects in 'practice'\n",
    "# series with integer and float variables summed.\n",
    "prescribing_data_cambridge_group = \\\n",
    "    prescribing_data_cambridge.groupby('practice').sum()\n",
    "    \n",
    "prescribing_data_leeds_group = \\\n",
    "    prescribing_data_leeds.groupby('practice').sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change index of practice dataframes to practice code to allow for\n",
    "# merging with prescribing dataframes.\n",
    "cambridge_practices.set_index('practice_code', inplace=True)\n",
    "leeds_practices.set_index('practice_code', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cambridge_merged = \\\n",
    "    pd.merge(left=cambridge_practices, \\\n",
    "             right=prescribing_data_cambridge_group, \\\n",
    "             left_index=True, right_index=True)\n",
    "    \n",
    "leeds_merged = \\\n",
    "    pd.merge(left=leeds_practices, \\\n",
    "             right=prescribing_data_leeds_group, \\\n",
    "             left_index=True, right_index=True)\n",
    "    \n",
    "leeds_merged.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `groupby()` function in pandas can take a column header as an argument and group each unique value in that column into a single row. Here it is used for the `'bnf name'` column, with associated values added up in each of the new rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grouping prescribing data by drug names. Variables within\n",
    "# groups added together.\n",
    "presscribing_data_grouped_drugs_leeds = \\\n",
    "    prescribing_data_leeds.groupby('bnf name').sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top 10 most prescribed drugs across all practices in England:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort dataframe by number of items in descending order.\n",
    "presscribing_data_grouped_drugs_leeds.sort_values(by='items', \n",
    "                                                  ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list containing the 10 least prescribed drugs would offer little value as there were 1648 drugs prescribed only once in December 2015 in England.\n",
    "\n",
    "This list may contain different doses of the same drug so it may not accurately how much that particular drug was prescribed in total however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the length of series, for which variable in items\n",
    "# column is equal to 1.\n",
    "len(presscribing_data_grouped_drugs_leeds.loc\\\n",
    "    [presscribing_data_grouped_drugs_leeds['items'] == 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total cost of the 10 most prescribed drugs in December 2015 was £361,109.49\n",
    "The total cost of the 1648 drugs only prescribed once was £135,290.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the sum of cost for the largest 10 values for items.\n",
    "sum(presscribing_data_grouped_drugs_leeds\\\n",
    "    .sort_values(by='items', ascending=False).head(10)['act cost'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the sum of the drugs only prescribed once.\n",
    "sum(presscribing_data_grouped_drugs_leeds.loc\\\n",
    "    [presscribing_data_grouped_drugs_leeds['items'] == 1]['act cost'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total spend on prescriptions by all practices in Leeds during this time period is £10,152,241.24\n",
    "The mean spend was £67,681.60 and the median spend was £48,660.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the total spend of all leeds practices\n",
    "sum(leeds_merged['act cost'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the mean of cost for all practices in the Leeds\n",
    "# merged practice dataframe.\n",
    "np.mean(leeds_merged['act cost'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns the median of cost for all practices in the Leeds\n",
    "# merged practice dataframe.\n",
    "np.median(leeds_merged['act cost'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 1648 least prescribed drugs and 10 most prescribed drugs Leeds accounted for 1.33% and 3.56% of spending, repectively, during December of 2015  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(presscribing_data_grouped_drugs_leeds.loc\\\n",
    "    [presscribing_data_grouped_drugs_leeds['items'] == 1]\\\n",
    "    ['act cost'])/sum(leeds_merged['act cost'])*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(presscribing_data_grouped_drugs_leeds\\\n",
    "    .sort_values(by='items', ascending=False).head(10)['act cost'])\\\n",
    "    /sum(leeds_merged['act cost'])*100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the 10 most expensive prescriptions made in Leeds during December 2015, I first created a new column containing the average cost of each drug prescribed. This values in this column were set as equal to the division of the actual cost by items.\n",
    "\n",
    "This list may not reflect the cost of the drugs themselves. E.g. the most expensive prescription made in Leeds during this time period is for 'Tocoph Acet_Tab Chble 100mg'. However, 1080 tablets were included in this prescription. Large prescriptions may misrepresnt the cost of what may otherwise cheap drug.\n",
    "\n",
    "Alternatively I could work out the cost per unit of drug in a prescription. This, however, may also misrepresent the cost of drugs in the data as some drugs, such as methadone are administed in small incraments of 1ml. Due to this, without understanding the standardised dosage per patient, per time period, using 'quantity' to calculate the most/least expensive drugs may cause similar problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a new column, where each variable is total cost/prescriptions\n",
    "# to give mean cost per prescription of drug.\n",
    "presscribing_data_grouped_drugs_leeds['cost_per_drug'] = \\\n",
    "    presscribing_data_grouped_drugs_leeds['act cost'] \\\n",
    "    /presscribing_data_grouped_drugs_leeds['items']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this new column, the dataframe could be sorted by by the cost of the drug in a descending order, with the first 10 values being showed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns a dataframe with each row representing a drug,\n",
    "# sorted by mean cost per prescription of drug, in descending order.\n",
    "presscribing_data_grouped_drugs_leeds.sort_values('cost_per_drug',\n",
    "                                                  ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The average GP practice in Cambridge porduces 29% more prescriptions than the average Leeds practice. As illustrated in the boxplot bellow, this appears to be due to a large number of practices in leeds that made very few prescriptions in December 2015. \n",
    "\n",
    "The values for the upper quartiles of prescriptions given out in Leeds and Cambridge GP practices were 14120 and 14512 respectively. This indicates that much of the difference between prescribing between the two cities does come from a large number of practices in Leeds that do not make many prescriptions as opposed to a substantial number of practices in Cambridge that provide a larger than average number of prescriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Mean number of prescriptions made in Leeds GP preactices: %.2f'\n",
    "      % np.mean(prescribing_data_leeds_group['items']))\n",
    "print('Mean number of prescriptions made in Cambridge GP preactices: %.2f'\n",
    "      % np.mean(prescribing_data_cambridge_group['items']))\n",
    "\n",
    "print('\\nMean spend per prescription in Leeds GP preactices: £%.2f'\n",
    "      % (np.mean(prescribing_data_leeds_group['act cost'])\\\n",
    "      / np.mean(prescribing_data_leeds_group['items'])))\n",
    "print('Mean spend per prescription in Cambridge GP preactices: £%.2f'\n",
    "      % (np.mean(prescribing_data_cambridge_group['act cost'])\\\n",
    "      / np.mean(prescribing_data_cambridge_group['items'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a dictionary for font options in plot.\n",
    "bold_dict = {'size': 14,\n",
    "             'weight': 'bold'}\n",
    "\n",
    "# Returns matplotlib boxplot comparing the distribution of GP practices\n",
    "# in Cambridge and Leeds by number of prescriptions made\n",
    "plt.boxplot([prescribing_data_leeds_group['items'],\n",
    "             prescribing_data_cambridge_group['items']],\n",
    "            labels = ['Leeds', 'Cambridge'],\n",
    "            vert = False,\n",
    "            widths = 0.6)\n",
    "plt.title('Distribution of Quantity of Prescriptions\\nMade by GP Practices ' +\n",
    "          'In Cambridge and Leeds', fontdict=bold_dict)\n",
    "plt.xlabel('Number of Prescriptions per Practice', fontdict=bold_dict)\n",
    "plt.gcf().set_size_inches(11,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('The 75th percentile of prescriptions per practice for Leeds was: %d'\n",
    "      % np.percentile(prescribing_data_leeds_group['items'], 75))\n",
    "print('The 75th percentile of prescriptions per practice for Cambridge was: %d'\n",
    "      % np.percentile(prescribing_data_cambridge_group['items'], 75))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of GP practices relative cost per prescription, for both Leeds and Cambridge differ in that there is a greater range for Leeds practices. There are also several outliers in the Leeds practices, with a high spend per prescription that skew the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates a numpy array called <city>_spend_prescription, where each\n",
    "# each value is the relative cost per prescription for a practice.\n",
    "leeds_spend_prescription = \\\n",
    "    np.array(prescribing_data_leeds_group['act cost'] /\n",
    "             prescribing_data_leeds_group['items'])\n",
    "\n",
    "cambridge_spend_prescription = \\\n",
    "    np.array(prescribing_data_cambridge_group['act cost'] /\n",
    "             prescribing_data_cambridge_group['items'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plots a histogram representing the distribution of the relative costs\n",
    "# per prescription in Leeds and Cambridge.\n",
    "# Arranged in to 50 bins of equal width.\n",
    "# Data is normalised as the absolute frequency of Leeds is higher\n",
    "# due to having more data.\n",
    "bold_dict = {'size': 14,\n",
    "             'weight': 'bold'}\n",
    "plt.hist([leeds_spend_prescription, cambridge_spend_prescription],\n",
    "         50, alpha=0.85,  color=['b', 'r'],\n",
    "         label=['Leeds', 'Cambridge'], normed=True)\n",
    "plt.title('Distribution of Relative Cost Per Prescription for\\nGP Practices ' +\n",
    "          'In Cambridge and Leeds', fontdict=bold_dict)\n",
    "plt.legend()\n",
    "plt.xlabel('Relative cost per prescription (£)', fontdict=bold_dict)\n",
    "plt.ylabel('Frequency of GP practices', fontdict=bold_dict)\n",
    "\n",
    "plt.gcf().set_size_inches(11,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Horizontal boxplot, illustrating distribution of <city>_spend_prescription\n",
    "# arrays for Leeds and Cambridge data.\n",
    "bold_dict = {'size': 14,\n",
    "             'weight': 'bold'}\n",
    "plt.boxplot([leeds_spend_prescription, cambridge_spend_prescription],\n",
    "            labels=['Leeds', 'Cambridge'],\n",
    "            vert=False, widths=0.6)\n",
    "plt.title('Distribution of Relative Cost Per Prescription for GP Practices\\n' +\n",
    "          'In Cambridge and Leeds', fontdict=bold_dict)\n",
    "plt.xlabel('Relative cost per prescription (£)', fontdict=bold_dict)\n",
    "plt.xlim(0,20)\n",
    "plt.gcf().set_size_inches(11,4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this SQL query, practice codes were counted by grouped cities and regions, as many practices in the `practice_data_all` dataframe have their city value stored as a region and vice versa. Practices are then ordered by their count in a descending order.\n",
    "\n",
    "For both practice lists grouped by city and region, the modal category was a blank string, i.e. there were more practices, for which this data wsa missing than the next highest city/region. To show the top 10 in descending order, index based positions were used to take a slice of indexes 1 to 10, with a all columns (city first, then count). Simply removing the `.iloc` function form this code will produce a table of practice counts from this query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         city  COUNT(practice_code)\n",
      "1   BIRMINGHAM                                  173\n",
      "2   LIVERPOOL                                   137\n",
      "3   LEEDS                                       122\n",
      "4   MANCHESTER                                  117\n",
      "5   SHEFFIELD                                   105\n",
      "6   BRISTOL                                      95\n",
      "7   COVENTRY                                     95\n",
      "8   LONDON                                       92\n",
      "9   BRADFORD                                     85\n",
      "10  LEICESTER                                    84\n"
     ]
    }
   ],
   "source": [
    "print(pdsql(\"SELECT COUNT(practice_code), city\\\n",
    "       FROM practice_data_all\\\n",
    "       GROUP BY city\\\n",
    "       ORDER BY COUNT(practice_code)\\\n",
    "       DESC\", locals()).iloc[1:11, [1, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       region  COUNT(practice_code)\n",
      "1   LONDON                                      869\n",
      "2   ESSEX                                       410\n",
      "3   KENT                                        398\n",
      "4   LANCASHIRE                                  339\n",
      "5   WEST MIDLANDS                               314\n",
      "6   SURREY                                      278\n",
      "7   MIDDLESEX                                   245\n",
      "8   WEST YORKSHIRE                              234\n",
      "9   CHESHIRE                                    213\n",
      "10  HAMPSHIRE                                   184\n"
     ]
    }
   ],
   "source": [
    "print(pdsql(\"SELECT COUNT(practice_code), region\\\n",
    "       FROM practice_data_all\\\n",
    "       GROUP BY region\\\n",
    "       ORDER BY COUNT(practice_code)\\\n",
    "       DESC\", locals()).iloc[1:11, [1, 0]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By merging national prescribing data (grouped by practice code) with national practice data, the new `all_practices_merged` dataframe contains the total spending for each practice in England, under the 'act cost' column header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a new dataframe from prescribing data, grouped by\n",
    "# practice, with numberical variables within group added.\n",
    "prescribing_data_all_grouped = \\\n",
    "    prescribing_data_all.groupby('practice').sum()\n",
    "\n",
    "# Merging this new dataframe with practice data(with practice\n",
    "# code as its index).\n",
    "all_practices_merged = \\\n",
    "    pd.merge(left=practice_data_all.set_index('practice_code'),\n",
    "            right = prescribing_data_all_grouped,\n",
    "            left_index=True, right_index=True)\n",
    "\n",
    "all_practices_merged.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The total number of prescriptions given out in England during December 2015'\n",
    "       + ' is: ' + str(sum(prescribing_data_all_grouped['items'])) \n",
    "      \n",
    "      + '\\n\\nThe total spent on prescriptions during this time period is: £'\n",
    "      + str(sum(prescribing_data_all_grouped['act cost']))\n",
    "     \n",
    "      + '\\n\\nThe mean number of prescriptions given out by GP practices in England was: ' \n",
    "      + str(int(np.mean(prescribing_data_all_grouped['items'])))\n",
    "      \n",
    "      + '\\n\\nThe median number of prescriptions given out by GP practices in England was: '\n",
    "      + str(np.median(prescribing_data_all_grouped['items']))\n",
    "     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to calculate the mean cost per patient for each practice, the HSCIC GP demographic information dataset was imported intp a Pandas data frame. Setting the index of this dataframe as being the practice code, allowed for it to be easily merged with the practice dataframe (also with practice codes as its index).\n",
    "\n",
    "The all_practices_with_demo dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the GP practice demographic data as a pandas dataframe 'demo_data'\n",
    "# with GP practice code as index.\n",
    "demo_data = pd.read_csv('https://digital.nhs.uk/media/28273/Numbers-of-' +\n",
    "                        'Patients-Registered-at-a-GP-Practice-Jan-2016-GP-' +\n",
    "                        'Practice-and-quinary-age-groups/Any/gp-reg-patients' +\n",
    "                        '-prac-quin-age', index_col=[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging GP practice dataframe with demographic data.\n",
    "all_practices_with_demo = \\\n",
    "    pd.merge(left=all_practices_merged,\n",
    "            right = demo_data, \n",
    "            left_index=True, right_index=True)\n",
    "    \n",
    "all_practices_with_demo.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the columns from the practice and demographic data are not informative when investigating the total number of patients registered at each practice and their average cost of prescriptions. By removing unecessary columns, the data is clearer and easier to interpret.\n",
    "\n",
    "Using the `np.r_` method to concatenate a combination of indexes and slices, the `all_practices_cost_per_patient` variable was reassigned to a copy of itself, excluding irrelevant columns. This left only columns 0, 3, 5, 6, 7, 8, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subsetting the practice + demographic dataframe, to only include\n",
    "# variables relevant to this analysis. Assigning this subset\n",
    "# to 'all_practices_cost_per_patient'\n",
    "all_practices_cost_per_patient = \\\n",
    "    all_practices_with_demo.iloc[:, np.r_[0, 3,5:9,16]]\n",
    "all_practices_cost_per_patient.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dividing cost by number of registered patitents to return a series\n",
    "# of relative cost per patient for corresponding GP Practices.\n",
    "# Assigned to new column 'cost_per_patient'\n",
    "all_practices_cost_per_patient['cost_per_patient'] = \\\n",
    "    all_practices_cost_per_patient['act cost'] \\\n",
    "    /all_practices_cost_per_patient['Total_All']\n",
    "\n",
    "all_practices_cost_per_patient.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('The mean cost of prescriptions per patient in England during December 2015 was: £%.2f' \\\n",
    "      % np.mean(all_practices_cost_per_patient['cost_per_patient']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compare the cost per patient in Leeds GP practices, the all_practices_cost_per_patient dataframe was reindexed to move practice codes into a column and then subsetted based on rows that contained practice codes in Leeds.\n",
    "\n",
    "Both dataframes had their indexes reset to be the practice codes for each practice.\n",
    "\n",
    "There is a very strong correlation between number of patients registered at a GP practice and how much it spends on prescriptions for both England as a whole (r² = 0.769) and Leeds (r² = 0.560). The national correlation coefficient is higher than that of Leeds, though this could be to more data points reducing the effect of outliers.\n",
    "\n",
    "The `stats.linregress()` function of `scipy` returns a special type of list, containing descriptive statistics on the linear regression of two variables from a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_practices_cost_per_patient.reset_index(inplace=True)\n",
    "\n",
    "leeds_practices_cost_per_patient = \\\n",
    "    all_practices_cost_per_patient.loc[all_practices_cost_per_patient['index']\n",
    "                                       .str.contains\n",
    "                                       ('|'.join(leeds_practice_codes))]\n",
    "\n",
    "all_practices_cost_per_patient.set_index('index', inplace=True)\n",
    "leeds_practices_cost_per_patient.set_index('index', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assigning the 'get current figure' function of matplotlib as axes\n",
    "axes = plt.gcf()\n",
    "\n",
    "bold_dict = {'size': 14,\n",
    "             'weight': 'bold'}\n",
    "\n",
    "# Creating two scatter plots, with total number of registered patients\n",
    "# per practice, plotted against total spend per practice.\n",
    "plt.scatter(all_practices_cost_per_patient['Total_All'],\n",
    "            all_practices_cost_per_patient['act cost'],\n",
    "            marker='o')\n",
    "plt.scatter(leeds_practices_cost_per_patient['Total_All'],\n",
    "            leeds_practices_cost_per_patient['act cost'],\n",
    "            color='r', marker='o')\n",
    "\n",
    "plt.legend(['England', 'Leeds'])\n",
    "plt.ylim(0,600000)\n",
    "plt.xlim(0,40000)\n",
    "plt.title('The Relationship Between Spending and ' +\n",
    "          'Number of Registered Patients', fontdict=bold_dict)\n",
    "plt.xlabel('Number of Registered Patients', fontdict=bold_dict)\n",
    "plt.ylabel('Total Cost of Prescriptions', fontdict=bold_dict)\n",
    "\n",
    "axes.set_size_inches(15,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stats.linregress()[2] returns the correlation coefficient for\n",
    "# these data. Their exponents of 2 gives the r² values.\n",
    "regress_england = \\\n",
    "    stats.linregress(all_practices_cost_per_patient['Total_All'],\n",
    "                     all_practices_cost_per_patient['act cost'])\\\n",
    "                     [2] ** 2\n",
    "\n",
    "regress_leeds = \\\n",
    "    stats.linregress(leeds_practices_cost_per_patient['Total_All'],\n",
    "                     leeds_practices_cost_per_patient['act cost'])\\\n",
    "                     [2] ** 2\n",
    "\n",
    "print('England r² = %.3f\\nLeeds r² = %.3f' % (regress_england, regress_leeds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "axes = plt.gcf()\n",
    "\n",
    "bold_dict = {'size': 14,\n",
    "             'weight': 'bold'}\n",
    "\n",
    "plt.hist(all_practices_cost_per_patient['cost_per_patient'],\n",
    "         range=(5, 30), bins = 30, color='#E67E22', alpha=0.8)\n",
    "\n",
    "plt.title('Relative Costs Per Patient In GP Practices In England',\n",
    "          fontdict=bold_dict)\n",
    "plt.xticks(range(5,31))\n",
    "plt.xlabel('Relative costs per patient (£)', fontdict=bold_dict)\n",
    "plt.ylabel('Number of practices', fontdict=bold_dict)\n",
    "plt.ylim(0,800)\n",
    "axes.set_size_inches(15,10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a Leeds specific dataframe containing basic information about practices as well as their demographic data, a subset was created from the all_practices_with_demo dataframe. The .ix() method was used to select rows, for which the practice code contained within was of a Leeds GP practice.\n",
    "\n",
    "Alomost all of the practices with codes that began with the letter 'Y' were not referenced in the demographic data, therefore the columns could not previously have been merged and they contain Not a Number (NaN) as each variable.\n",
    "\n",
    "To remove practices with no data, the .dropna() method will be used. As the columns with missing data are missing data from all columns, I will tell the function to only drop rows for which all values are missing, so as not to remove any rows that might only be missing a small number of variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leeds_practices_with_demo  = \\\n",
    "    all_practices_with_demo.ix[leeds_practice_codes]\n",
    "leeds_practices_with_demo.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leeds_practices_with_demo.dropna(axis=0, how='all', inplace=True)\n",
    "leeds_practices_with_demo.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no descernable difference in the ratio of males to females, when comparing GP practices in Leeds as compared to those in England as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "england_male = sum(all_practices_with_demo['Total_Male'])\n",
    "england_female = sum(all_practices_with_demo['Total_Female'])\n",
    "\n",
    "england_male_proportion = england_male/(england_female+england_male)\n",
    "england_female_proportion = england_female/(england_female+england_male)\n",
    "\n",
    "leeds_male = sum(leeds_practices_with_demo['Total_Male'])\n",
    "leeds_female = sum(leeds_practices_with_demo['Total_Female'])\n",
    "\n",
    "leeds_male_proportion = leeds_male/(leeds_female+leeds_male)\n",
    "leeds_female_proportion = leeds_female/(leeds_female+leeds_male)\n",
    "\n",
    "axes = plt.gcf()\n",
    "fig, ax = plt.subplots(figsize=(5,7))\n",
    "x_ax = np.arange(2)\n",
    "width = 0.3\n",
    "b1 = ax.bar(x_ax, [england_male_proportion, leeds_male_proportion], width, label='Male')\n",
    "b2 = ax.bar(x_ax + width, [england_female_proportion, leeds_female_proportion] , width, label='Female')\n",
    "\n",
    "plt.ylim(0.4, 0.6)\n",
    "plt.yticks([0.4, 0.45, 0.5, 0.55, 0.6])\n",
    "plt.ylabel('Percentage')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create histograms of the age distribution for GP practices in Leeds and England, as a whole "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original bins for the age groups in the demographic data was sepperated by sex. To summarise the age distribution of all people, the values for each sex were added together and new bins were created, without reference to sex. These new bins were systematically created using a for loop to save time and prevent typing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 0\n",
    "age_bins = []\n",
    "for i in range(20):\n",
    "    age_bins.append(a)\n",
    "    a += 5\n",
    "age_bins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By manually creating bins, I have created a histrogram of the age distribution for GP practices in Leeds, using the bar chart function of matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "leeds_male_demographics = \\\n",
    "    pd.DataFrame(leeds_practices_with_demo.sum().iloc[19:39])\n",
    "leeds_female_demographics = \\\n",
    "    pd.DataFrame(leeds_practices_with_demo.sum().iloc[39:])\n",
    "\n",
    "leeds_male_and_female_ages = \\\n",
    "    np.array(leeds_male_demographics[0]) + \\\n",
    "    np.array(leeds_female_demographics[0])\n",
    "\n",
    "\n",
    "leeds_age_demographics = pd.DataFrame(leeds_male_and_female_ages, age_bins)\n",
    "\n",
    "all_male_demographics = \\\n",
    "    pd.DataFrame(all_practices_with_demo.sum().iloc[19:39])\n",
    "all_female_demographics = \\\n",
    "    pd.DataFrame(all_practices_with_demo.sum().iloc[39:])\n",
    "\n",
    "all_male_and_female_ages = \\\n",
    "    np.array(all_male_demographics[0]) + \\\n",
    "    np.array(all_female_demographics[0])\n",
    "\n",
    "\n",
    "all_age_demographics = pd.DataFrame(all_male_and_female_ages, age_bins)\n",
    "\n",
    "bold_dict = {'size': 14,\n",
    "             'weight': 'bold'}\n",
    "\n",
    "plt.bar(list(all_age_demographics.index), all_age_demographics[0], 5,\n",
    "        align='edge', color='#FA8072')\n",
    "\n",
    "plt.xlim(0, 100)\n",
    "plt.xticks(range(0, 101, 5))\n",
    "plt.title('Age Distribution In of Registered Patitents at Leeds GP Practices',\n",
    "          fontdict=bold_dict)\n",
    "plt.xlabel('Age', fontdict=bold_dict)\n",
    "plt.ylabel('Frequency', fontdict=bold_dict)\n",
    "\n",
    "plt.gcf().set_size_inches(9, 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that one prescription of a statin represents a patient, and that each patient is only prescribed one type of statin, once a month. This however causes some statins to be represented as being dispraportionatley expensive. For example, the liquid suspensions of atorvastatin, are prescribed as large quantities of doses in very few prescriptions.\n",
    "\n",
    "The demographic data used was recorded for the quarter, ending in January 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "england_patients = \\\n",
    "    sum(demo_data['Total_All'])\n",
    "    \n",
    "print('In total, there were %d patients in England ' +\n",
    "      'at the time of Janury 2016.' % england_patients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of statin drugs to search prescribing data for.\n",
    "statin_drugs = ['simvastatin', 'atorvastatin',\n",
    "                'rosuvastatin', 'pravastatin',\n",
    "                'fluvastatin']\n",
    "\n",
    "# Subset dataframe to only statins\n",
    "statin_prescriptions = \\\n",
    "    prescribing_data_all.loc[prescribing_data_all['bnf name']\n",
    "                             .str.contains('|'.join(statin_drugs), case=False)]\n",
    "\n",
    "# Group statin prescription dataframe by drug name.\n",
    "statin_prescriptions = \\\n",
    "    statin_prescriptions.groupby('bnf name').sum()\n",
    "\n",
    "statin_prescriptions.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statin Prescriptions:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating the relative cost per prescription\n",
    "statin_prescriptions['relative_cost_per_prescription'] = \\\n",
    "    statin_prescriptions['act cost']/statin_prescriptions['items']\n",
    "\n",
    "# Calculating the relative cost per patient\n",
    "statin_prescriptions['relative_cost_per_patient'] = \\\n",
    "    statin_prescriptions['act cost']/england_patients\n",
    "\n",
    "# Renaming columns for presentation\n",
    "statin_prescriptions.columns = ['Number of Prescriptions',\n",
    "                                'Total Spend on Drug (£)',\n",
    "                                'Total Units of Drug Prescribed',\n",
    "                                'Relative Cost of Drug per Prescription (£)',\n",
    "                                'Relative Cost of Drug per Patient (£)']\n",
    "\n",
    "# Round the columns containing monetery values to 2 decimal places\n",
    "money_columns = ['Total Spend on Drug (£)',\n",
    "                 'Relative Cost of Drug per Prescription (£)',\n",
    "                 'Relative Cost of Drug per Patient (£)']\n",
    "\n",
    "for i in money_columns:\n",
    "    statin_prescriptions[i] = statin_prescriptions[i]\\\n",
    "                              .apply(lambda x: np.round(x, decimals=2))\n",
    "\n",
    "statin_prescriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('For GP practices in England, during the month of December 2015:\\n\\n')\n",
    "\n",
    "print('The total number of statin prescriptions was: %d \\n'\n",
    "      % statin_prescriptions['Number of Prescriptions'].sum())\n",
    "\n",
    "print('The total spend on statin prescriptions was: £%d \\n'\n",
    "      % statin_prescriptions['Total Spend on Drug (£)'].sum())\n",
    "\n",
    "print('The mean cost per prescription of a statin was: £%.2f'\n",
    "      % np.mean(statin_prescriptions['Relative Cost of Drug per Prescription (£)']))\n",
    "print('The median cost per prescription of a statin was: £%.2f \\n'\n",
    "      % np.median(statin_prescriptions['Relative Cost of Drug per Prescription (£)']))\n",
    "\n",
    "print('The total cost of statins per patient in England was: £%.2f \\n'\n",
    "      % statin_prescriptions['Relative Cost of Drug per Patient (£)'].sum())\n",
    "\n",
    "statins_percent = \\\n",
    "    (statin_prescriptions['Total Spend on Drug (£)'].sum()\\\n",
    "     /prescribing_data_all['act cost'].sum())*100\n",
    "statins_percent = np.round(statins_percent, decimals=3)\n",
    "    \n",
    "    \n",
    "print('Statins made up %' + str(statins_percent) + ' of all prescription costs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The deprivation dataset was read into a pandas dataframe, named `imd`. Only the relevant columns of the dataset were imported. These included:\n",
    "* *'Postcode'* - Set as the index column, for the purpose of merging with GP prescribing data from Leeds and England as a whole.\n",
    "* *'Index of Multiple Deprivation Rank'* and *'Index of Multiple Deprivation Decile'* - for analysis of their relationship to statin prescriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading the IMD dataset as pandas dataframe imd\n",
    "url = \\\n",
    "    'https://s3.eu-west-2.amazonaws.com/dmhr-data/deprivation-by-postcode.csv'\n",
    "\n",
    "imd = pd.read_csv(url, usecols=['Postcode',\n",
    "                                'Index of Multiple Deprivation Rank',\n",
    "                                'Index of Multiple Deprivation Decile'],\n",
    "                  index_col='Postcode')\n",
    "imd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `leeds_practices_cost_per_patient` dataframe (with *practice code* replaced by *post code* as index) was merged with the `imd` dataframe. \n",
    "\n",
    "Once merged, the index of the new `leeds_imd` dataframe was reset and replaced with practices codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leeds_imd = pd.merge(left = leeds_practices_cost_per_patient.reset_index().set_index('post_code'),\n",
    "                    right = imd,\n",
    "                    left_index = True,\n",
    "                    right_index = True)\n",
    "leeds_imd.reset_index(inplace=True)\n",
    "leeds_imd.set_index('index', inplace=True)\n",
    "leeds_imd.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the presentation of the data, column headers and the index header were renamed. The columns were then rearranged using integer based positioning (`.iloc`) and `numpy.r_`, for concatenation of slices of these positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Renaming columns of leeds_imd dataframe\n",
    "leeds_imd.columns = ['post code',\n",
    "                     'practice name',\n",
    "                     'city',\n",
    "                     'prescriptions made',\n",
    "                     'total cost of prescriptions',\n",
    "                     'units of drug prescribed',\n",
    "                     'total number of patients',\n",
    "                     'cost per patient',\n",
    "                     'index of multiple deprivation rank',\n",
    "                     'index of multiple deprivation decile']\n",
    "\n",
    "# Renaming index header.\n",
    "leeds_imd.index.name = 'practice code'\n",
    "\n",
    "leeds_imd.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Assigning the leeds_imd dataframe to a concatenation of slices\n",
    "# of itself, in order to re-order the columns for presentation.\n",
    "leeds_imd = leeds_imd.iloc[:, np.r_[1 , 2 , 0 , 8:10 , 3:8 ]]\n",
    "leeds_imd.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A subset of the national GP prescribing dataframe was created, under the name of `england_statin_prescriptions`, with only the unique prescriptions of statin drugs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a subset of national prescribing data for statin drugs.\n",
    "england_statin_prescriptions = \\\n",
    "    prescribing_data_all.loc[prescribing_data_all['bnf name']\n",
    "                             .str.contains('|'.join(statin_drugs), case=False)]\n",
    "\n",
    "england_statin_prescriptions.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping by (`df.groupby()`) *practice* and the use of the *.sum()* method creates a new dataframe that summarises the numerical data for statin prescriptions in each English GP practice for the month of December 2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Grouping nationwide statin prescriptions by practice.\n",
    "england_statin_prescriptions = \\\n",
    "    england_statin_prescriptions.groupby(by='practice').sum()\n",
    "\n",
    "england_statin_prescriptions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging statin prescription data with demographic data.\n",
    "england_statin_prescriptions = \\\n",
    "    pd.merge(left=england_statin_prescriptions,\n",
    "             right=demo_data.iloc[:, np.r_[0, 3, 7]],\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "\n",
    "england_statin_prescriptions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging statin prescription by practice with relevant information\n",
    "# on practices\n",
    "england_statin_prescriptions = \\\n",
    "    pd.merge(left=england_statin_prescriptions,\n",
    "             right=practice_data_all.set_index('practice_code')\n",
    "                                    .iloc[:, np.r_[0:5]],\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "\n",
    "england_statin_prescriptions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting postcode as index for merginf with IMD data.\n",
    "england_statin_prescriptions.reset_index(inplace=True)\n",
    "england_statin_prescriptions.set_index('POSTCODE', inplace=True)\n",
    "\n",
    "# Strip trailing whitespace from imd index(postcodes)\n",
    "imd.index = imd.index.str.strip()\n",
    "\n",
    "# Merging statin prescription data + GP info with IMD data.\n",
    "england_statin_prescriptions = \\\n",
    "    pd.merge(left=england_statin_prescriptions,\n",
    "             right=imd,\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "\n",
    "england_statin_prescriptions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove duplicate rows\n",
    "england_statin_prescriptions.drop_duplicates(inplace=True)\n",
    "\n",
    "# Set index back to practice codes\n",
    "england_statin_prescriptions.reset_index(inplace=True)\n",
    "england_statin_prescriptions.set_index('index', inplace=True)\n",
    "\n",
    "# Re-ordering columns and renaming headers for better presentation.\n",
    "england_statin_prescriptions = \\\n",
    "    england_statin_prescriptions.iloc[ : , np.r_[6:11 , 0, 2, 1, 5, 4, 11, 12]]\n",
    "\n",
    "england_statin_prescriptions.columns = ['practice name' , \n",
    "                                       'building name' , \n",
    "                                       'street' , \n",
    "                                       'city' , \n",
    "                                       'region' , \n",
    "                                       'post code' , \n",
    "                                       'total statin spend (£)' , \n",
    "                                       'total statin prescriptions' ,\n",
    "                                        'total patients registered' ,\n",
    "                                       'ons region code' , \n",
    "                                       'index of multiple deprivation rank' , \n",
    "                                       'index of multiple deprivation decile']\n",
    "\n",
    "england_statin_prescriptions.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two practices do not have any data corresponding to IMD. These have been removed, as they cannot be used to investigate a link between index of multiple deprivation and statin prescriptions. Furthermore, removing NaN values will allow for the conversion of these two series to integer datatypes, as NaN can only be a float value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "england_statin_prescriptions.loc[~(england_statin_prescriptions['index of multiple deprivation rank'] > 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing all rows with IMD rank below 0\n",
    "england_statin_prescriptions = \\\n",
    "    england_statin_prescriptions\\\n",
    "    .loc[england_statin_prescriptions\n",
    "         ['index of multiple deprivation rank'] > 0]\n",
    "\n",
    "# Changing data type of IMD rank and decile from float to integer.\n",
    "england_statin_prescriptions.iloc[:, [10, 11]] = \\\n",
    "    england_statin_prescriptions.iloc[:, [10, 11]].astype(int)\n",
    "\n",
    "# Create a statin spend per person\n",
    "england_statin_prescriptions['relative statin spend'] = \\\n",
    "    england_statin_prescriptions['total statin spend (£)']\\\n",
    "    / england_statin_prescriptions['total patients registered']\n",
    "\n",
    "england_statin_prescriptions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lowest relative spenders of statins from the first decile\n",
    "lowest_decile = \\\n",
    "    england_statin_prescriptions\\\n",
    "    .loc[england_statin_prescriptions['index of multiple deprivation decile'] == 1]\n",
    "\n",
    "lowest_decile.sort_values('relative statin spend', ascending = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#highest relative spenders of statins from the last decile\n",
    "\n",
    "highest_decile = \\\n",
    "    england_statin_prescriptions\\\n",
    "    .loc[england_statin_prescriptions['index of multiple deprivation decile'] == 10]\n",
    "\n",
    "highest_decile.sort_values('relative statin spend', ascending = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculating the mean values for relative statin cost for the\n",
    "# lowest and highest deciles of IMD\n",
    "lowest_mean = np.mean(lowest_decile['relative statin spend'])\n",
    "highest_mean = np.mean(highest_decile['relative statin spend'])\n",
    "\n",
    "# Calculating the median values for relative statin cost for the\n",
    "# lowest and highest deciles of IMD\n",
    "lowest_median = np.median(lowest_decile['relative statin spend'])\n",
    "highest_median = np.median(highest_decile['relative statin spend'])\n",
    "\n",
    "print('The mean relative spend on statins, through prescriptions ' +\n",
    "      'given by GPs:\\n\\n' +\n",
    "      'In the first decile of the index of multiple ' +\n",
    "      'deprivation was: £%.2f \\n' % lowest_mean +\n",
    "      'In the tenth decile of the index of multiple ' +\n",
    "      'deprivation was: £%.2f \\n\\n' % highest_mean)\n",
    "\n",
    "print('The median relative spend on statins, through prescriptions ' +\n",
    "      'given by GPs:\\n\\n' +\n",
    "      'In the first decile of the index of multiple ' +\n",
    "      'deprivation was: £%.2f \\n' % lowest_median +\n",
    "      'In the tenth decile of the index of multiple ' +\n",
    "      'deprivation was: £%.2f ' % highest_median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the mean values was far greater than that of the median values, suggesting and outlier in the first decile.\n",
    "\n",
    "This outlier is GP practice E87723, NEW ELGIN PRACTICE in West London. This practice is reocreded as only having a single patient but having made 352 prescriptions for statins.\n",
    "\n",
    "Using its label based location reveals that this practice was recorded has having a single patient. However, searching the prescribing data for this practice reveals that there were 1104 prescriptions made in Dec 2015. Due to this, it is likely that this outlier is caused by an error in the demographic data. \n",
    "\n",
    "As this only affects one practice out of over 7000 ( < 0.02% of the data) I will drop it from the `england_statin_prescriptions` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns dataframe of practices with a large (over £1) relative\n",
    "# cost of statin prescriptions.\n",
    "england_statin_prescriptions.loc[england_statin_prescriptions\n",
    "                                 ['relative statin spend'] > 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns registered patient data for the anomalous practice 'E87723'.\n",
    "demo_data.loc['E87723', ['Total_Male', 'Total_Female', 'Total_All']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Returns shape precribing data for preactice E87723\n",
    "prescribing_data_all.loc[prescribing_data_all['practice']\n",
    "                         .str.contains('E87723')].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Removing practice E87723 from the statin prescription data.\n",
    "england_statin_prescriptions.drop('E87723', axis=0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lowest_decile = \\\n",
    "    england_statin_prescriptions\\\n",
    "    .loc[england_statin_prescriptions\n",
    "         ['index of multiple deprivation decile'] == 1]\n",
    "\n",
    "lowest_mean = np.mean(lowest_decile['relative statin spend'])\n",
    "lowest_median = np.median(lowest_decile['relative statin spend'])\n",
    "\n",
    "print('The new mean relative spend on statins ' +\n",
    "      'in the first decile is: £%.2f \\n'\n",
    "      % lowest_mean +\n",
    "      'The new median relative spend on statins ' +\n",
    "      'in the first decile is: £%.2f \\n'\n",
    "      % lowest_median)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is little difference to the distribution of spending on statin prescriptions between the 10 deciles of IMD, as illustrated by the box plot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Empty list to loop through\n",
    "imd_deciles = []\n",
    "\n",
    "# Creates a list of numpy arrays, with each array containing the\n",
    "# values for relative statin prescription spending for each decile.\n",
    "for i in range(1,11):\n",
    "    imd_deciles.append(np.array(england_statin_prescriptions\n",
    "                       .loc[england_statin_prescriptions\n",
    "                            ['index of multiple deprivation decile'] == i]\n",
    "                            ['relative statin spend']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = []\n",
    "for i in range(1,11):\n",
    "    u.append('Decile ' + str(i))\n",
    "u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bold_dict = {'size': 14,\n",
    "             'weight': 'bold'}\n",
    "\n",
    "plt.boxplot(imd_deciles,\n",
    "            labels=['Decile 1', 'Decile 2',\n",
    "                    'Decile 3', 'Decile 4',\n",
    "                    'Decile 5', 'Decile 6',\n",
    "                    'Decile 7', 'Decile 8',\n",
    "                    'Decile 9', 'Decile 10'])\n",
    "\n",
    "plt.ylim(0,1)\n",
    "axes = plt.gcf()\n",
    "axes.set_size_inches(11,8)\n",
    "\n",
    "plt.yticks([0.0, 0.1, 0.2, 0.3, 0.4, 0.5,\n",
    "            0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "plt.title('Relatve Statin Spend Per Patient By IMD Decile', fontdict=bold_dict)\n",
    "plt.ylabel('Relatve Statin Spend Per Patient (£)', fontdict=bold_dict)\n",
    "plt.xlabel('Decile', fontdict=bold_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Practices that are in the lowest decile of **relative costs of statin prescriptions** tend to be of a lower IMD rank, as illustrated in the boxplot below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "england_statin_prescriptions.sort_values('relative statin spend',\n",
    "                                         ascending=True, inplace=True)\n",
    "\n",
    "x = int(len(england_statin_prescriptions)/10)\n",
    "\n",
    "top_10_percent_statins = \\\n",
    "    np.array(england_statin_prescriptions\n",
    "             ['index of multiple deprivation rank'].tail(x))\n",
    "\n",
    "bottom_10_percent_statins = \\\n",
    "    np.array(england_statin_prescriptions\n",
    "             ['index of multiple deprivation rank'].head(x))\n",
    "\n",
    "plt.boxplot([top_10_percent_statins,\n",
    "            bottom_10_percent_statins],\n",
    "            labels=['Top Decile', 'Bottom Decile'])\n",
    "\n",
    "plt.ylabel('IMD Rank', fontdict=bold_dict)\n",
    "plt.xlabel('Decile of Statin Cost', fontdict=bold_dict)\n",
    "plt.title('IMD Ranks of The Practices That Have the Highest and\\n' +\n",
    "          'Lowest Relative Cost Of Statin Prescriptions', fontdict=bold_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(bottom_10_percent_statins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.mean(top_10_percent_statins)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the lowest and highest spenders of the practices in the catchment area of the least and most deprived areas respectively, gives the `both_spend_groups` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "both_spend_groups = \\\n",
    "    pd.concat([lowest_decile.sort_values('relative statin spend', ascending=True).head(100), \n",
    "               highest_decile.sort_values('relative statin spend', ascending=False).head(100)],\n",
    "               axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the *75 mortality rate for cardiovascular diseases* dataset as `cvd75`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvd75 = \\\n",
    "    pd.read_csv('https://s3.eu-west-2.amazonaws.com/dmhr' +\n",
    "                '-data/NHSOF_1.1_I00656_D.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvd75.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to extract regional data, a `df.column_head.unique()` query was utilised to find which column contained region names and what exactly the names were, in order to create a subset dataframe.\n",
    "\n",
    "To conduct a query of unique values, all column names changed to not have space. A function to replace spaces with underscores may have been more practical with more column headers. However, as there were relatively few, manually renaming was faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvd75.columns = ['year', 'period', 'breakdown', 'level',\n",
    "                 'level_description', 'gender', 'age', 'indicator_value',\n",
    "                 'lower_ci', 'upper_ci', 'numerator', 'denominator']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvd75.level_description.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the unique values in the level description column, the exact phrases reffering to the nine English regions were copied into a list. This list was used to create a new dataframe (`cvd75_regions`), containing only rows that made reference to each region **and** the year 2015 **and** all genders ('Person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nine_english_regions = ['East Midlands', 'East of England', 'London',\n",
    "                        'North East', 'North West', 'South East', 'South West',\n",
    "                        'West Midlands', 'Yorkshire and The Humber']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvd75_regions_2015 = cvd75.loc[cvd75['level_description'].str.contains\n",
    "                               ('|'.join(nine_english_regions)) &\n",
    "                               (cvd75['year'] == 2015) & \n",
    "                               (cvd75['gender'] == 'Person')]\n",
    "\n",
    "cvd75_regions_2015\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *ONS Postcode Lookup* dataset can be used to link GP practices to thier corresponding region, through their postcode. Only the columns at index 2 (postcode) and 16 (region code) were needed, so to save memory, only these two were read into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "postcode = pd.read_csv('https://s3.eu-west-2.amazonaws.com/dmhr-data/postcodes.csv',\n",
    "                       usecols=[2, 16], index_col=0)\n",
    "postcode.columns = ['region_code']\n",
    "postcode.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postcode.region_code.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that there is a dataframe that links each postcode to its corresponding region code, it can be seen that there are more unique region codes than contained within the CVD75 dataset. The additional region codes do not follow the same naming convention. \n",
    "\n",
    "Rows in the `postcode` dataframe that contained a region code, not foiund in the `cvd75_regions_2015` dataframe were filtered out. Rows wiht NaN values were also removed from the `postcode` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "region_codes = list(cvd75_regions_2015['level'])\n",
    "region_codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postcode.dropna(axis=0, inplace=True)\n",
    "\n",
    "postcode = \\\n",
    "    postcode.loc[postcode['region_code'].str.contains('|'.join(region_codes))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `postcode` now only contains rows, for which the region code is one of the nine from the `cvd75_regions_2015` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "postcode.region_code.unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new column was created with a lambda function that added a cell with the region name corresponding to the region code of that row. A dictionary was used to match the key (region code) to the value (region name).\n",
    "\n",
    "As dictionaries are mutable, a loop could have been created to add region codes and thier corresponding names to a dictionary. However, at only 9 key-value pairs, doing this manually would have been more time efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "english_regions = {'E12000004' : 'East Midlands',\n",
    "                   'E12000006' : 'East of England',\n",
    "                   'E12000007' : 'London',\n",
    "                   'E12000001' : 'North East',\n",
    "                   'E12000002' : 'North West',\n",
    "                   'E12000008' : 'South East',\n",
    "                   'E12000009' : 'South West',\n",
    "                   'E12000005' : 'West Midlands',\n",
    "                   'E12000003' : 'Yorkshire and The Humber'}\n",
    "\n",
    "postcode['region_name'] = postcode['region_code'].apply(lambda x: english_regions[x])\n",
    "\n",
    "postcode.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `postcode` dataframe can now be merged with the `england_statin_prescriptions` dataframe to add information about which of the 9 English regions the GP practices belong to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = len(england_statin_prescriptions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "england_statin_prescriptions.reset_index(inplace=True)\n",
    "england_statin_prescriptions.set_index('post code', inplace=True)\n",
    "\n",
    "england_statin_prescriptions = pd.merge(left = england_statin_prescriptions,\n",
    "                                         right = postcode,\n",
    "                                         left_index=True,\n",
    "                                         right_index=True)\n",
    "\n",
    "england_statin_prescriptions.reset_index(inplace=True)\n",
    "england_statin_prescriptions.set_index('index', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process of merging the two dataframes, 31 rows were not carried over. This could be due to the rows not having a postcode corresponding to the `postcode` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = len(england_statin_prescriptions)\n",
    "x - y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "england_statin_prescriptions.head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "england_statin_prescriptions.columns = ['post code', 'practice name',\n",
    "                                        'building name', 'street', 'city',\n",
    "                                        'region', 'total statin spend (£)',\n",
    "                                        'total statin prescriptions',\n",
    "                                        'total patients registered',\n",
    "                                        'ons region code',\n",
    "                                        'index of multiple deprivation rank',\n",
    "                                        'index of multiple deprivation decile',\n",
    "                                        'relative statin spend', 'region code',\n",
    "                                        'region name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "england_statin_prescriptions.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping the `england_statin_prescriptions` dataframe by region code and calculating the mean of their relative spend on statin prescriptions. This dataframe, containing the mean statin spend per region was merged with the `cvd75` dataframe. Finally, only the columns corresponding to mortality rates and relative cost of statin prescriptions were included in the new `cvd75_and_statins` dataframe.\n",
    "\n",
    "There is a weak correlation (*r²* = 0.15) between spending on statins and CVD75 mortality rates in England. However, practices in London spend substantially less on statin prescriptions than other regions of comparable mortality rates. Due to this, I beleive that there may a confounder influencing the spend on statins per patient. \n",
    "\n",
    "When London is excluded from analysis, the correlation between spending on statins and CVD75 mortality rates in England becomes moderate to strong (*r²* = 0.429).\n",
    "\n",
    "Furthermore the data points appear to cluster based on geographic proximity. With the exception of London, these clusters include:\n",
    "\n",
    "* The South (East of England, South East, South West)\n",
    "* The Midlands (East Midlands, West Midlands)\n",
    "* The North (North East, North West, Yorkshire and The Humber)\n",
    "\n",
    "Regions that are higher in lattitude (with the exception of London) appear to have significantly\\* higher mortality rates. At a glance there does not appear to be as strong a relationship between lattitude and statin spending alone. Further analysis could use coordiantes, linked with practice codes to assess geographical factors and their relationship to statin spending and mortality.\n",
    "\n",
    "\\* Significance from confidence intervals provided in the CVD75 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "region_statins = \\\n",
    "    england_statin_prescriptions.groupby('region name').mean()\n",
    "    \n",
    "cvd75_and_statins = \\\n",
    "    pd.merge(left = cvd75_regions_2015.set_index('level_description'),\n",
    "             right = region_statins,\n",
    "             left_index = True,\n",
    "             right_index = True)\n",
    "\n",
    "cvd75_and_statins = \\\n",
    "    cvd75_and_statins.iloc[: , [6, 7, 8, 16]]\n",
    "    \n",
    "cvd75_and_statins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indicator values (mortality rate) are stored as strings. They will be converted into floats. This will make them easier to handle when graphing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvd75_and_statins['indicator_value'].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_float = ['indicator_value',\n",
    "                    'lower_ci',\n",
    "                    'upper_ci']\n",
    "\n",
    "for i in columns_to_float:\n",
    "    cvd75_and_statins[i] = cvd75_and_statins[i].apply(lambda x: float(x))\n",
    "    print(i + ' : ' + str(cvd75_and_statins[i].dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_line(x_vals, y_vals, line_colour, line_style, label_name):\n",
    "    m = stats.linregress(x_vals, y_vals)[0]\n",
    "    b = stats.linregress(x_vals, y_vals)[1]\n",
    "    x_1 = 0.15\n",
    "    x_steps = 0.01\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in range(16):\n",
    "        x.append(x_1)\n",
    "        y_val = ((x_1*m) + b)\n",
    "        y.append(y_val)\n",
    "        x_1 += x_steps\n",
    "    plt.plot(x,y, c=line_colour, ls=line_style, label=label_name, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "axes = plt.gcf()\n",
    "\n",
    "plot_df = cvd75_and_statins\n",
    "x_val = plot_df['relative statin spend']\n",
    "y_val = plot_df['indicator_value']\n",
    "\n",
    "point_labels = list(plot_df.index.values)\n",
    "point_colour = '#2ECC71'\n",
    "\n",
    "bold_dict = {'size': 14,\n",
    "             'weight': 'bold'}\n",
    "\n",
    "plt.scatter(x_val, y_val, c=point_colour, s=100)\n",
    "\n",
    "for i, j in enumerate(point_labels):\n",
    "    plt.annotate(j, (plot_df['relative statin spend'][i],\n",
    "                     plot_df['indicator_value'][i]))\n",
    "\n",
    "axes.set_size_inches(15, 9)\n",
    "plt.title('The Relationship Between Statin Prescriptions\\nand ' +\n",
    "          'The Mortality Rate of Under-75s From\\nCardiovascular Disease',\n",
    "          fontdict=bold_dict)\n",
    "plt.xlabel('Relative Spend on Statins (£)', fontdict=bold_dict)\n",
    "plt.ylabel('Under-75 Mortality rate from CVD', fontdict=bold_dict)\n",
    "plt.xlim(0.15, 0.30)\n",
    "plt.ylim(50, 100)\n",
    "plt.yticks([50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100])\n",
    "plt.xticks([0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25,\n",
    "            0.26, 0.27, 0.28, 0.29, 0.30])\n",
    "\n",
    "\n",
    "plot_line(x_val, y_val, 'k', '--', 'Linear Regression')\n",
    "\n",
    "text_box = 'r² = %.3f' % (stats.linregress(x_val, y_val)[2] ** 2)\n",
    "\n",
    "axes.text(0.91, 0.65, s=text_box, fontdict=bold_dict)\n",
    "\n",
    "y_error_vals = ([abs(y_val - plot_df['lower_ci']),\n",
    "                 abs(y_val - plot_df['upper_ci'])])\n",
    "\n",
    "plt.gca().errorbar(x_val, y_val, yerr=y_error_vals, fmt='none', c=point_colour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_error_vals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.corrcoef(cvd75_and_statins['relative statin spend'],\n",
    "             cvd75_and_statins['indicator_value'])[1,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.linregress(cvd75_and_statins['relative statin spend'],\n",
    "                cvd75_and_statins['indicator_value'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When London is exluded from the dataset, a stronger correlation emerges between relative spend on statins and under 75 mortality from CVD. Is London an anomoly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cvd_no_london = cvd75_and_statins.loc[cvd75_and_statins.index != 'London']\n",
    "np.corrcoef(cvd_no_london['relative statin spend'],\n",
    "             cvd_no_london['indicator_value'])[1,0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats.linregress(cvd_no_london['relative statin spend'],\n",
    "                cvd_no_london['indicator_value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "axes = plt.gcf()\n",
    "\n",
    "plot_df = cvd_no_london\n",
    "x_val = plot_df['relative statin spend']\n",
    "y_val = plot_df['indicator_value']\n",
    "\n",
    "point_labels = list(plot_df.index.values)\n",
    "point_colour = 'y'\n",
    "\n",
    "bold_dict = {'size': 14,\n",
    "             'weight': 'bold'}\n",
    "\n",
    "plt.scatter(x_val, y_val, c=point_colour, s=100)\n",
    "\n",
    "for i, j in enumerate(point_labels):\n",
    "    plt.annotate(j, (plot_df['relative statin spend'][i],\n",
    "                     plot_df['indicator_value'][i]))\n",
    "\n",
    "axes.set_size_inches(15, 9)\n",
    "plt.title('The Relationship Between Statin Prescriptions\\nand ' +\n",
    "          'The Mortality Rate of Under-75s\\nFrom Cardiovascular Disease\\n' +\n",
    "          '(Without Data From London)', fontdict=bold_dict)\n",
    "plt.xlabel('Relative Spend on Statins (£)', fontdict=bold_dict)\n",
    "plt.ylabel('Under-75 Mortality rate from CVD', fontdict=bold_dict)\n",
    "plt.xlim(0.15, 0.30)\n",
    "plt.ylim(50, 100)\n",
    "plt.yticks([50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100])\n",
    "plt.xticks([0.15, 0.16, 0.17, 0.18, 0.19, 0.20, 0.21, 0.22, 0.23, 0.24, 0.25,\n",
    "            0.26, 0.27, 0.28, 0.29, 0.30])\n",
    "\n",
    "\n",
    "plot_line(x_val, y_val, 'r', '--', 'Linear Regression')\n",
    "\n",
    "text_box = 'r² = %.3f' % (stats.linregress(x_val, y_val)[2] ** 2)\n",
    "\n",
    "axes.text(0.91, 0.65, s=text_box,\n",
    "          fontdict=bold_dict)\n",
    "\n",
    "y_error_vals = ([abs(y_val - plot_df['lower_ci']),\n",
    "                 abs(y_val - plot_df['upper_ci'])])\n",
    "\n",
    "plt.gca().errorbar(x_val, y_val, yerr=y_error_vals, fmt='none', c=point_colour)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For this assignment, I will be importing Google flu trend data for Germany and Chile. As these datasets are stored in a `.txt` format, I will use the `pandas.read_table()` function. As `.txt` and `.csv` are both 'flat files', the data is parsed in a simmilar manner and can take the same arguments and parsing options. In both datasets, the headers are on the 8th row and the first column contains dates in a format, easily recognised and parsed by pandas. Instead of using the `pandas.to_datetime` function, less code is required to parse the date column as a datetime series during the reading in stage.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "germany_flu = \\\n",
    "    pd.read_table('https://www.google.org/flutrends/' +\n",
    "                  'about/data/flu/de/data.txt',\n",
    "                  sep=',', header=8, parse_dates=[0])\n",
    "germany_flu.set_index('Date', inplace=True)\n",
    "\n",
    "chile_flu = \\\n",
    "    pd.read_table('https://www.google.org/flutrends/' +\n",
    "                  'about/data/flu/cl/data.txt',\n",
    "                  sep=',', header=8, parse_dates=[0])\n",
    "chile_flu.set_index('Date', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Germany date format: %s\\nChile date format: %s'\n",
    "      % (germany_flu.index.dtype, chile_flu.index.dtype))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "axes = plt.gcf()\n",
    "date = germany_flu.index.values\n",
    "\n",
    "# Both the data for flu trends in Germany and Chile were divided\n",
    "# by their maximum value to normalise the data.\n",
    "plt.plot(germany_flu['Germany']/max(germany_flu['Germany']))\n",
    "plt.plot(chile_flu['Chile']/max(chile_flu['Chile']))\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.xlim(min(date), max(date))\n",
    "plt.title('Flu Trends in Germany & Chile', fontdict=bold_dict)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Relative Frequency')\n",
    "\n",
    "axes.set_size_inches(15, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same plot, with a smoother line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "axes = plt.gcf()\n",
    "\n",
    "# Resampling both plots with a trailing mean of\n",
    "# 2 months to give a smoother line\n",
    "(germany_flu['Germany']/max(germany_flu['Germany']))\\\n",
    "    .resample('2M', how='mean').plot()\n",
    "\n",
    "(chile_flu['Chile']/max(chile_flu['Chile']))\\\n",
    "    .resample('2M', how='mean').plot()\n",
    "\n",
    "plt.legend()\n",
    "plt.xlim(pd.Timestamp('2004-01-01'), pd.Timestamp('2015-08-01'))\n",
    "plt.title('Flu Trends in Germany & Chile', fontdict=bold_dict)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Relative Frequency')\n",
    "\n",
    "axes.set_size_inches(15, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Grouping the dataframes for Germany and Chile by index year, then applying the `.min()` and `.max()` functions gave the yearly minimum and maximum frequencies by year. Merging These dataframes together gives the anual minimum and maximum frequencies for Germany and Chile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "germany_minmax = \\\n",
    "    pd.merge(left=pd.DataFrame(germany_flu.groupby\n",
    "                               ([germany_flu.index.year]).max()['Germany']),\n",
    "             right=pd.DataFrame(germany_flu.groupby\n",
    "                                ([germany_flu.index.year]).min()['Germany']),\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "germany_minmax.columns = ['Germany Annual Maximum', 'Germany Annual Minimum']\n",
    "\n",
    "chile_minmax = \\\n",
    "    pd.merge(left=pd.DataFrame(chile_flu.groupby\n",
    "                               ([chile_flu.index.year]).max()['Chile']),\n",
    "             right=pd.DataFrame(chile_flu.groupby\n",
    "                                ([chile_flu.index.year]).min()['Chile']),\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "chile_minmax.columns = ['Chile Annual Maximum', 'Chile Annual Minimum']\n",
    "\n",
    "all_minmax =\\\n",
    "    pd.merge(left=germany_minmax,\n",
    "             right=chile_minmax,\n",
    "             left_index=True,\n",
    "             right_index=True)\n",
    "\n",
    "all_minmax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the flu trends for Germany are more consistent, year on year, I will be using this as the basis for my model. Furthermore, I will use the 2 month trailing mean of Germany flu trends as a benchmark for my model. This is due to this transformtation showing more general seasonal trends, less affected by sudden spikes, for which I will not be aiming to predict.\n",
    "\n",
    "Each increment of 1 on the x axis of my model will correspond to a single week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(0.5, 140.6, 2)\n",
    "y = (np.sin(x/1.9 + 1.5) + 1.9) / 4\n",
    "\n",
    "model_1 = pd.DataFrame(y, x)\n",
    "\n",
    "model_1.plot(label='Model')\n",
    "plt.xlim(0, 120)\n",
    "plt.yticks()\n",
    "plt.gcf().set_size_inches(15, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to plot my model against the data for German flu trends, both plots need to be on the same x-scale. Timestamp values in the date column will be converted into integers. Due to the running average, each value corresponds the the end of the month in intervals of two months, starting on the 31st-Jan-04.\n",
    "\n",
    "As each time is on the last day of its corresponding month, I will consider each interval as being half way between its month and the next. \n",
    "\n",
    "For example, as January is coded as 0 on the scale, the first entry of 31/01 would be 0.5. The next entry is two months later on 31/03, which will be 2.5, followed by 4.5, 6.5, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "germany_flu_scale = \\\n",
    "    (germany_flu['Germany']/max(germany_flu['Germany']))\\\n",
    "    .resample('2M', how='mean').reset_index().iloc[2:, :]\n",
    "\n",
    "germany_flu_scale['date_int'] = np.arange(0.5, 142, 2)\n",
    "\n",
    "germany_flu_scale.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "germany_flu_scale = \\\n",
    "    (germany_flu['Germany']/max(germany_flu['Germany']))\\\n",
    "    .resample('2M', how='mean').reset_index().iloc[2:, :]\n",
    "\n",
    "germany_flu_scale['date_int'] = np.arange(0.5, 142, 2)\n",
    "\n",
    "germany_flu_scale.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Pearson correlation coefficient: ' +\n",
    "      str(stats.pearsonr(model_1[0], germany_flu_scale['Germany'])[0]))\n",
    "\n",
    "plt.plot(germany_flu_scale['date_int'], germany_flu_scale['Germany'])\n",
    "\n",
    "plt.plot(model_1, label='Model 1')\n",
    "\n",
    "plt.xlim(0, 120)\n",
    "plt.yticks()\n",
    "plt.legend()\n",
    "\n",
    "plt.gcf().set_size_inches(15, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjustments to the mathematical function were made to better fit the data. These modifications yielded a higher correlation coefficient, suggesting a closer relationship and therefore a better model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(0.5, 140.6, 2)\n",
    "y = (np.sin(x/1.9 + 0.9) + 1.6) / 5\n",
    "\n",
    "model_2 = pd.DataFrame(y, x)\n",
    "print('Pearson correlation coefficient: ' +\n",
    "      str(stats.pearsonr(model_2[0], germany_flu_scale['Germany'])[0]))\n",
    "\n",
    "plt.plot(germany_flu_scale['date_int'], germany_flu_scale['Germany'])\n",
    "plt.plot(model_2, label='Model 2')\n",
    "plt.xlim(0, 120)\n",
    "plt.yticks()\n",
    "plt.legend()\n",
    "\n",
    "plt.gcf().set_size_inches(15, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Increasing the number of points plotted against the model gives a smoother curve.\n",
    "\n",
    "This model reflects the general seasonal trends of flu in Germany. It does not, however, account for or predict accurately years, for which there is a spike in flu related searches or a lower than usual occurence. More data would be needed to search for a possible correlation that might suggest an answer and therefore some measure to predict these changes.\n",
    "\n",
    "A loop could have been created to fine tune the equation in small increments to produce a more accurate curve. However, I believe that carrying this process out manually did suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.arange(0.5, 140.6, 0.1)\n",
    "y = (np.sin(x/1.9 + 0.9) + 1.6) / 5\n",
    "\n",
    "plt.plot(germany_flu_scale['date_int'], germany_flu_scale['Germany'])\n",
    "plt.plot(x, y, label='Model 2')\n",
    "\n",
    "plt.xlim(0, 120)\n",
    "plt.yticks()\n",
    "plt.legend()\n",
    "plt.title('Google Flu Trends From Germany and Predictive Model 2',\n",
    "          fontdict=bold_dict)\n",
    "plt.ylabel('Relative Frequency', fontdict=bold_dict)\n",
    "plt.xlabel('Month From January 2004', fontdict=bold_dict)\n",
    "\n",
    "plt.gcf().set_size_inches(15, 4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
